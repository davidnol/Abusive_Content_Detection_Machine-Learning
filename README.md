## Online Abusive Content Detection: Classical versus Deep Learning
A number of challenges exist when it comes to detecting online abusive content. Choosing the appropriate classifiers, identifying the optimum feature representation, and dealing with unbalanced datasets are all difficulties that need to be addressed. The Support Vector Machines (SVM) classifier approach has dominated text categorization in recent decades. Since the development of Deep Neural Networks (DNN), there has been a shift in emphasis to deep learning and word embeddings. The purpose of this dissertation is to compare and contrast what has been used in the past with what is today considered cutting-edge in terms of identifying online harmful content.

This dissertation incorporated deep learning convolutional and recursive neural networks. To ensure results based on a diverse set of data, the method here makes use of 3 public datasets with varying degrees of imbalance. The first focus of this dissertation is on pre-trained word embeddings on data that is in line with the classification data, to test the impact on prediction and detection accuracy of models utilizing deep learning (DL) techniques. Three research papers were focused on in order to emulate and verify the results of the dataset and techniques used by [Davidson et al., 2017] namely Logistic Regression (LR) and Support Vector Machines (SVM), [Waseem and Hovy, 2016] utilizing LR and [Pitsilis et al., 2018] utilizing RNN (LSTM) and the [Waseem and Hovy, 2016] labeled dataset.

After that, the focus changes to the effect on different classifiers to different degrees of training set imbalance. A review of the effect of bias and comparison for abusive language datasets for [Waseem and Hovy, 2016], [Davidson et al., 2017] and [Founta, et al., 2018] is carried out in a bid to decipher datasets that are most suitable for training generalizable classifiers.

The results of this study can help researchers choose acceptable text classification algorithms for detecting abusive content, even in situations when the training datasets are skewed along with choosing datasets that are most suitable for training generalizable classifiers.
